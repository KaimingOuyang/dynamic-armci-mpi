               ARMCI Over MPI RMW Implementation Notes
               =======================================

Direct access to local buffers:

 * Because of MPI's semantics, you are not allowed to access shared memory
   directly, it must be through put/get.  Alternatively you can use the 
   new ARMCI_Access_begin/end() functions.
   
 * Both buffers in a communication operation should not be in shared space.
   MPI allows locking only one window at a time so this cannot be supported
   except for special cases.


ARMCI groups:

 * ARMCI-style groups are not currently supported.  Groups formation is
   currently collective across the parent group (MPI-style).  In ARMCI-style it
   is collective across only the processes in the new group.

 * Note: ARMCI-style groups are not ARMCI's default behavior, they must be
   explicitly enabled.  ARMCI's default behavior is to use MPI-style groups.


Progress semantics:

 * Most MPI implementations will require you to do something in order to enable
   implicit the progress needed by ARMCI.  You'll need to set an environment
   variable in most cases. MPICH_ASYNC_PROGRESS for MPICH2, something else for
   MVAPICH2, DCMF_INTERRUPTS=1 for MPICH2-BG, etc.
